{
  "apiKey": "",
  "openrouterApiKey": "",
  "anthropicApiKey": "",
  "geminiApiKey": "",
  "openaiUrl": "https://api.openai.com",
  "openrouterUrl": "https://openrouter.ai",
  "ollamaUrl": "http://localhost:11434",
  "lmstudioUrl": "http://localhost:1234",
  "anthropicUrl": "https://api.anthropic.com",
  "geminiUrl": "https://generativelanguage.googleapis.com",
  "chatFolder": "ChatGPT_MD/chats",
  "chatTemplateFolder": "ChatGPT_MD/templates",
  "stream": true,
  "generateAtCursor": false,
  "autoInferTitle": false,
  "pluginSystemMessage": "You're chatting with a user in Obsidian, a knowledge management system where they organize notes in interconnected Markdown files. This conversation appears as a chat within their active document.\n\nBe helpful and concise. Use proper Markdown: ```language for code blocks, `inline` for code/filenames. Support [[Internal Links]] and [external links](url). Consider this chat is part of their personal knowledge base.\n\nWhen appropriate, end with an open question to keep the conversation helpful and make contextual offers based on their last message.",
  "dateFormat": "YYYYMMDDhhmmss",
  "headingLevel": 3,
  "inferTitleLanguage": "English",
  "defaultChatFrontmatter": "---\nsystem_commands: ['You are a helpful assistant.']\nfrequency_penalty: 0\nmax_tokens: 400\nmodel: ollama@llama3.2\npresence_penalty: 0\nstream: true\ntemperature: 0.7\n---",
  "openaiDefaultModel": "openai@gpt-4.1-mini",
  "openaiDefaultTemperature": 0.7,
  "openaiDefaultTopP": 1,
  "openaiDefaultMaxTokens": 400,
  "openaiDefaultPresencePenalty": 0,
  "openaiDefaultFrequencyPenalty": 0,
  "anthropicDefaultModel": "anthropic@claude-sonnet-4-20250514",
  "anthropicDefaultTemperature": 0.7,
  "anthropicDefaultMaxTokens": 400,
  "geminiDefaultModel": "gemini@gemini-2.5-flash",
  "geminiDefaultTemperature": 0.7,
  "geminiDefaultTopP": 0.95,
  "geminiDefaultMaxTokens": 400,
  "openrouterDefaultModel": "openrouter@openai/gpt-4.1-mini",
  "openrouterDefaultTemperature": 0.7,
  "openrouterDefaultTopP": 1,
  "openrouterDefaultMaxTokens": 400,
  "openrouterDefaultPresencePenalty": 0.5,
  "openrouterDefaultFrequencyPenalty": 0.5,
  "ollamaDefaultTemperature": 0.7,
  "ollamaDefaultTopP": 1,
  "lmstudioDefaultTemperature": 0.7,
  "lmstudioDefaultTopP": 1,
  "lmstudioDefaultPresencePenalty": 0,
  "lmstudioDefaultFrequencyPenalty": 0
}